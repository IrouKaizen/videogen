{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'transformers'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-8736e78a8efc>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0maudioread\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mPIL\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mImage\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mtransformers\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mpipeline\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mset_seed\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtransformers\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mGPT2Tokenizer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mAutoModelForCausalLM\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mjson\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'transformers'"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import audioread\n",
    "from PIL import Image\n",
    "from transformers import pipeline, set_seed\n",
    "from transformers import GPT2Tokenizer, AutoModelForCausalLM\n",
    "import json\n",
    "import urllib\n",
    "import os\n",
    "import pysrt\n",
    "import whisper\n",
    "from gtts import gTTS\n",
    "from moviepy.editor import *\n",
    "from moviepy.video.tools.subtitles import SubtitlesClip\n",
    "from icrawler.builtin import GoogleImageCrawler\n",
    "from moviepy.config import change_settings\n",
    "from moviepy.video.fx.all import crop\n",
    "import re\n",
    "import os\n",
    "import pysrt\n",
    "from moviepy.editor import VideoFileClip\n",
    "import whisper\n",
    "import datetime\n",
    "import torch\n",
    "import re\n",
    "import logging\n",
    "import threading\n",
    "import configparser\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: Could not find a version that satisfies the requirement autoread\n",
      "ERROR: No matching distribution found for autoread\n"
     ]
    }
   ],
   "source": [
    "pip install autoread"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Load configuration from a config file\n",
    "config = configparser.ConfigParser()\n",
    "config.read('config.ini')\n",
    "\n",
    "# Getting configurations from config\n",
    "max_filename_length = int(config['General']['max_filename_length'])\n",
    "logs_dir = config['General']['logs_dir']\n",
    "general_log = config['General']['general_log']\n",
    "google_api_key = config['API']['google_custom_search_api_key']\n",
    "search_engine_id = config['API']['search_engine_id']\n",
    "\n",
    "\n",
    "# Get the search query from the user\n",
    "query = input(\"Enter search query: \")\n",
    "\n",
    "# Truncate the query to the maximum filename length\n",
    "filename = query[:min(len(query), max_filename_length)]\n",
    "\n",
    "# Replacing all non-alphanumeric characters with a hyphen using regular expression\n",
    "filename = re.sub('[^0-9a-zA-Z.-]+', '-', filename)\n",
    "\n",
    "\n",
    "#settingfilepaths\n",
    "output_dir = \"output\"\n",
    "image_dir = os.path.join(output_dir,filename)\n",
    "audio_dir = os.path.join(output_dir,'audio')\n",
    "video_dir = os.path.join(output_dir,'video')\n",
    "subtitle_dir = os.path.join(output_dir,'subtitle')\n",
    "# keeping the logs file seperate\n",
    "llm_log = os.path.join(logs_dir,'results.txt')\n",
    "\n",
    "\n",
    "#create directories function\n",
    "def create_dir(dir_path):\n",
    "    os.makedirs(dir_path, exist_ok= True)\n",
    "    print(f'created {dir_path} directory')\n",
    "\n",
    "\n",
    "create_dir(logs_dir)\n",
    "\n",
    "# Initialize logging\n",
    "logging.basicConfig(filename = os.path.join(logs_dir,general_log), level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "\n",
    "# logging the filename\n",
    "logging.info(f'Filename: {filename}')\n",
    "\n",
    "def change_settings(settings):\n",
    "    try:\n",
    "        # Your existing settings change code...\n",
    "        print(\"Hardware acceleration is set to: \", settings[\"FFMPEG_HWACCEL\"])\n",
    "\n",
    "    except Exception as e:\n",
    "        print(\"An error occurred when trying to use hardware acceleration: \", e)\n",
    "        print(\"Falling back to running FFmpeg without hardware acceleration.\")\n",
    "        \n",
    "        # Modify settings to not use hardware acceleration\n",
    "        settings[\"FFMPEG_HWACCEL\"] = None\n",
    "        settings[\"FFMPEG_VIDEO_CODEC\"] = \"h264\"\n",
    "        \n",
    "        # Your existing settings change code...\n",
    "        print(\"Hardware acceleration is set to: \", settings[\"FFMPEG_HWACCEL\"])\n",
    "\n",
    "# Call the function with your settings\n",
    "change_settings({ \n",
    "    \"FFMPEG_HWACCEL\": \"auto\",\n",
    "    \"FFMPEG_VIDEOPRESET\": \"fast\",\n",
    "    \"FFMPEG_VIDEO_CODEC\": \"h264\"\n",
    "})\n",
    "\n",
    "\n",
    "# Step 1: Search for interesting topics\n",
    "def search_topic(query, api_key, search_engine_id):\n",
    "    try:\n",
    "        url = f\"https://www.googleapis.com/customsearch/v1?key={api_key}&cx={search_engine_id}&q={query}\"\n",
    "        res = requests.get(url)\n",
    "        data = json.loads(res.text)\n",
    "        return data.get('items', [])\n",
    "    except Exception as e:\n",
    "        logging.error(f'Error in search_topic: {str(e)}')\n",
    "        return []\n",
    "\n",
    "width, height = (1920, 1080)\n",
    "\n",
    "# Step 2: Gather media\n",
    "def gather_media(query):\n",
    "    try:\n",
    "        create_dir(image_dir)\n",
    "        google_Crawler = GoogleImageCrawler(storage ={'root_dir': image_dir})\n",
    "        print(filename)\n",
    "        google_Crawler.crawl(keyword=query, min_size=(width, height), max_size=None, max_num=200)\n",
    "        images = os.listdir(image_dir)\n",
    "        return [os.path.join(image_dir, image) for image in images]\n",
    "    except Exception as e:\n",
    "        logging.error(f'Error in gather_media: {str(e)}')\n",
    "        return []\n",
    "\n",
    "device = torch.device('cuda:0') if torch.cuda.is_available() else torch.device('cpu')\n",
    "device_id = device.index\n",
    "# Define a function to generate text using the model\n",
    "def generate_text(description):\n",
    "\n",
    "    prefix =\"A well-crafted and beautifully written script for a video generation program, with a focus on balance and harmony.\"\n",
    "\n",
    "    # set_seed(seed)\n",
    "    seed = 1\n",
    "\n",
    "    model_name = \"gpt2\"\n",
    "    \n",
    "    model = AutoModelForCausalLM.from_pretrained(model_name)\n",
    "    tokenizer = GPT2Tokenizer.from_pretrained(model_name)\n",
    "    try:\n",
    "        generator = pipeline('text-generation',\n",
    "                             max_new_tokens=1000,\n",
    "                             model=model,\n",
    "                             tokenizer=tokenizer,\n",
    "                             prefix = prefix,\n",
    "                             device=device_id,\n",
    "                             temperature=1,\n",
    "                             top_k=50,\n",
    "                             top_p=1,\n",
    "                             repetition_penalty=1.2,\n",
    "                             length_penalty=0.5,\n",
    "                             do_sample=True,\n",
    "                             num_beams=4,\n",
    "                             no_repeat_ngram_size=3,\n",
    "                             num_return_sequences=1,\n",
    "                             )\n",
    "\n",
    "        # Generate text\n",
    "        additional_sentences_ = (generator(description)[0]['generated_text'])\n",
    "        additional_sentences = additional_sentences_\n",
    "\n",
    "        # Delete the model to free GPU memory\n",
    "        del generator\n",
    "        del model\n",
    "        torch.cuda.empty_cache()\n",
    "\n",
    "        return additional_sentences\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        logging.error(f'error in generator pipeline :{str(e)}')\n",
    "    \n",
    "    prompt = description\n",
    "    # Open the file in append mode and write the log\n",
    "    with open(llm_log, \"a\") as f:\n",
    "        # Write the timestamp\n",
    "        timestamp = datetime.datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "        f.write(f\"Timestamp: {timestamp}\\n\")\n",
    "\n",
    "        # Write the seed value\n",
    "        f.write(f\"Seed value: {seed}\\n\")\n",
    "\n",
    "        # Write the model parameters\n",
    "        f.write(f\"Model parameters: {model.config}\\n\")\n",
    "\n",
    "        # Write the input prompt\n",
    "        f.write(f\"Input prompt: {prompt}\\n\")\n",
    "\n",
    "        # Generate the text and write it to the log\n",
    "        f.write(f\"Generated text:\\n{additional_sentences}\\n\\n\")\n",
    "\n",
    "\n",
    "# Step 3: Create audio\n",
    "def create_audio(description):\n",
    "    \n",
    "    try:\n",
    "\n",
    "        create_dir(audio_dir)\n",
    "        # Use a pre-trained language model to generate additional sentences based on the initial description\n",
    "        \n",
    "        additional_sentences = generate_text(description)\n",
    "\n",
    "        print(f\"Generated audio for: {additional_sentences}\")\n",
    "        \n",
    "\n",
    "        # Concatenate the original description with the additional sentences\n",
    "        # text = \" \".join([description] + [additional_sentences])\n",
    "        text = additional_sentences\n",
    "        # Generate audio file using gTTS\n",
    "        tts = gTTS(text=text, lang='en')\n",
    "        tts.save(os.path.join(audio_dir, filename + '.mp3'))\n",
    "        return additional_sentences\n",
    "    except Exception as e:\n",
    "        logging.error(f'Error in create_audio: {str(e)}')\n",
    "        return description\n",
    "\n",
    "# Step 4: Create video\n",
    "def create_video(images, audio_file):\n",
    "    try:\n",
    "        create_dir(video_dir)\n",
    "        with audioread.audio_open(audio_file) as f:\n",
    "            audio_duration = int(f.duration)\n",
    "        image_duration = 3\n",
    "        print('Total Duration: {} seconds'.format(audio_duration))\n",
    "\n",
    "        num_loops = int(audio_duration / image_duration)\n",
    "        print('number of loops:{}'.format(num_loops))\n",
    "\n",
    "        width, height = (1920, 1080)\n",
    "\n",
    "        clips = []\n",
    "        i = 0\n",
    "        while True:\n",
    "            print(\"in while\")\n",
    "            for image in images:\n",
    "                try:\n",
    "                    clip = ImageClip(image).resize(width=width, height=height).crop(x1=0, y1=0, x2=width, y2=height).set_duration(image_duration)\n",
    "                    clips.append(clip)\n",
    "                    i = i + 1\n",
    "                except Exception as e:\n",
    "                    print(f\"Error opening image: {image}. Error message: {str(e)}\")\n",
    "            if i >= num_loops:\n",
    "                print(\"in if\")\n",
    "                break\n",
    "        print(\"after while\")\n",
    "        concat_clip = concatenate_videoclips(clips, method=\"compose\")\n",
    "        audio = AudioFileClip(audio_file)\n",
    "        video = concat_clip.set_audio(audio)\n",
    "        video.write_videofile(os.path.join(video_dir, filename + '.mp4'), fps=24)\n",
    "    except Exception as e:\n",
    "        logging.error(f'Error in create_video: {str(e)}')\n",
    "\n",
    "def generate_subtitle(audio_file):\n",
    "    try:\n",
    "        create_dir(subtitle_dir)\n",
    "        # Load the transcription model and transcribe the audio file\n",
    "        try:\n",
    "            model = whisper.load_model(\"base\", device=\"cuda\")\n",
    "            result = model.transcribe(audio_file)\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "            model = whisper.load_model(\"base\", device=\"cpu\")\n",
    "            result = model.transcribe(audio_file)\n",
    "\n",
    "        # Extract the transcribed text and segments from the result\n",
    "        text = result[\"text\"]\n",
    "        segments = result[\"segments\"]\n",
    "\n",
    "        # Generate subtitle files\n",
    "        subtitles = pysrt.SubRipFile()\n",
    "        for i, seg in enumerate(segments):\n",
    "            start_time = int(seg[\"start\"] * 1000)  # Convert start time to milliseconds\n",
    "            end_time = int(seg[\"end\"] * 1000)  # Convert end time to milliseconds\n",
    "            subtitle = pysrt.SubRipItem(index=i, start=pysrt.SubRipTime(milliseconds=start_time),\n",
    "                                        end=pysrt.SubRipTime(milliseconds=end_time), text=seg[\"text\"])\n",
    "            subtitles.append(subtitle)\n",
    "\n",
    "        # Save the subtitle file\n",
    "        subtitles.save(os.path.join(subtitle_dir, filename + '.srt'))\n",
    "    except Exception as e:\n",
    "        logging.error(f'Error in generate_subtitle: {str(e)}')\n",
    "\n",
    "def add_subtitles(video_file):\n",
    "    try:\n",
    "        create_dir(video_dir)\n",
    "        # Load the subtitles from the subtitle file\n",
    "        subs = pysrt.open(os.path.join(subtitle_dir, filename + \".srt\"))\n",
    "\n",
    "        # Check if there are subtitles available\n",
    "        if subs:\n",
    "            # Add the subtitles to the video file\n",
    "            video = VideoFileClip(video_file)\n",
    "            generator = lambda text: TextClip(text, font='Arial-Bold',\n",
    "                                              fontsize=32, \n",
    "                                              color='white',\n",
    "                                              bg_color='aqua')\n",
    "            sub = SubtitlesClip(os.path.join(subtitle_dir, filename + \".srt\"), generator)\n",
    "            video = CompositeVideoClip([video, sub.set_pos(('center', 'bottom'))])\n",
    "            video.write_videofile(os.path.join(video_dir, filename + 'with_subs.mp4'))\n",
    "        else:\n",
    "            print(\"No subtitles found\")\n",
    "    except Exception as e:\n",
    "        logging.error(f'Error in add_subtitles: {str(e)}')\n",
    "\n",
    "# Define main function\n",
    "def main():\n",
    "    try:\n",
    "        # Step 1: Search for interesting topics\n",
    "        search_results = search_topic(query, google_api_key, search_engine_id)\n",
    "        if search_results:\n",
    "            title = search_results[0]['title']\n",
    "            description = search_results[0]['snippet']\n",
    "            print(\"\\nDescription\\n\" + description + \"\\n\")\n",
    "\n",
    "            url = search_results[0]['link']\n",
    "\n",
    "            # Step 2: Gather media\n",
    "            media_links = gather_media(query)\n",
    "            print(len(media_links))\n",
    "\n",
    "            # Step 3: Create audio\n",
    "            create_audio(description)\n",
    "\n",
    "            generate_subtitle(os.path.join(audio_dir, filename + '.mp3'))\n",
    "\n",
    "            # Step 4: Create video\n",
    "            create_video(media_links, os.path.join(audio_dir, filename + '.mp3'))\n",
    "\n",
    "            # Step 5: Add subtitles\n",
    "            add_subtitles(os.path.join(video_dir, filename + '.mp4'))\n",
    "    except Exception as e:\n",
    "        logging.error(f'Error in main: {str(e)}')\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
